{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af04b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from operator import methodcaller\n",
    "\n",
    "\n",
    "seed = 42  \n",
    "old_data_path = \"./datasets\"\n",
    "new_save_path = './splits'\n",
    "split_per = 0.1\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.makedirs(new_save_path, exist_ok=True)\n",
    "\n",
    "for dataset_file in os.listdir(old_data_path):\n",
    "    if \"1b_benchmark\" in dataset_file:\n",
    "        continue\n",
    "    dataset_name = dataset_file.split(\".\")[0]\n",
    "    data_path = os.path.join(old_data_path, dataset_file)\n",
    "    with open(data_path) as file:\n",
    "        data = file.read().splitlines()\n",
    "    data = np.array(data)\n",
    "    split = np.random.random(len(data))\n",
    "    condition = split < split_per\n",
    "    train_split = np.arange(len(data))[~condition]\n",
    "    val_split = np.arange(len(data))[condition]\n",
    "    train_data = [str(text) for text in data[train_split]]\n",
    "    with open(os.path.join(new_save_path, f\"{dataset_name}.train.txt\"), \"w+\") as f:\n",
    "        f.write(\"\\n\".join(train_data))\n",
    "        \n",
    "    val_data = [str(text) for text in data[val_split]]\n",
    "    with open(os.path.join(new_save_path, f\"{dataset_name}.val.txt\"), \"w+\") as f:\n",
    "        f.write(\"\\n\".join(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8c9876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=1 python train.py -t finetune -i datasets/4dim.train.txt -p best.pretrain.model -o best.4dim.model\n",
      "CUDA_VISIBLE_DEVICES=1 python train.py -t finetune -i datasets/news.train.txt -p best.pretrain.model -o best.news.model\n",
      "CUDA_VISIBLE_DEVICES=1 python train.py -t finetune -i datasets/products.train.txt -p best.pretrain.model -o best.products.model\n",
      "CUDA_VISIBLE_DEVICES=1 python train.py -t finetune -i datasets/questions.train.txt -p best.pretrain.model -o best.questions.model\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"4dim\", \"news\", \"products\", \"questions\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"CUDA_VISIBLE_DEVICES=1 python train.py -t finetune -i datasets/{dataset}.train.txt -p best.pretrain.model -o best.{dataset}.model\")\n",
    "    # print(f\"CUDA_VISIBLE_DEVICES=1 python train.py -t finetune -i datasets/{dataset}.train.txt -p best.pretrain.model -o best.{dataset}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e842f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=1 python evaluate.py -m best.4dim.model -i datasets/4dim.train.txt -o outputs/outputs_4dim.txt -t classification -l inline\n",
      "CUDA_VISIBLE_DEVICES=1 python evaluate.py -m best.news.model -i datasets/news.train.txt -o outputs/outputs_news.txt -t classification -l inline\n",
      "CUDA_VISIBLE_DEVICES=1 python evaluate.py -m best.products.model -i datasets/products.train.txt -o outputs/outputs_products.txt -t classification -l inline\n",
      "CUDA_VISIBLE_DEVICES=1 python evaluate.py -m best.questions.model -i datasets/questions.train.txt -o outputs/outputs_questions.txt -t classification -l inline\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(f\"CUDA_VISIBLE_DEVICES=1 python evaluate.py -m best.{dataset}.model -i datasets/{dataset}.train.txt -o outputs/outputs_{dataset}.txt -t classification -l inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52dcae28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=3 python train.py -t finetune -i splits/4dim.train.txt -val-path splits/4dim.val.txt -p best.lm.model -o best.4dim.model -epoch 50 -batch-size 128 -max-len 200 -lr 1e-3\n",
      "CUDA_VISIBLE_DEVICES=3 python train.py -t finetune -i splits/news.train.txt -val-path splits/news.val.txt -p best.lm.model -o best.news.model -epoch 50 -batch-size 128 -max-len 200 -lr 1e-3\n",
      "CUDA_VISIBLE_DEVICES=3 python train.py -t finetune -i splits/products.train.txt -val-path splits/products.val.txt -p best.lm.model -o best.products.model -epoch 50 -batch-size 128 -max-len 200 -lr 1e-3\n",
      "CUDA_VISIBLE_DEVICES=3 python train.py -t finetune -i splits/questions.train.txt -val-path splits/questions.val.txt -p best.lm.model -o best.questions.model -epoch 50 -batch-size 128 -max-len 200 -lr 1e-3\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"4dim\", \"news\", \"products\", \"questions\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"CUDA_VISIBLE_DEVICES=3 python train.py -t finetune -i splits/{dataset}.train.txt -val-path splits/{dataset}.val.txt -p best.lm.model -o best.{dataset}.model -epoch 50 -batch-size 128 -max-len 200 -lr 1e-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a298c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
